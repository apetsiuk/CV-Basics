{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMgX0k8CYzBG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Computer Vision: Basic Functionality\n",
        "\n",
        "## Covered topics:\n",
        "\n",
        "- Image and video capture from camera\n",
        "- Video processing\n",
        "- Save processed video\n",
        "- Camera calibration\n",
        "- ArUCo markers generation\n",
        "- ArUCo markers detection\n",
        "- Pose estimation\n",
        "- Perspective projection"
      ],
      "metadata": {
        "id": "e5qsOTBzY1eZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "A9t18akynTiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os, glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "QhlUj48qnWtL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image capture from camera"
      ],
      "metadata": {
        "id": "gdbsobrwY5zk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_rgb = cv2.imread(\"img.jpeg\")\n",
        "gray = cv2.imread('img.jpg', 0)[:,10:1700]\n",
        "\n",
        "red = image_rgb[:,:,0] # get blue channel\n",
        "green = image_rgb[:,:,1] # get green channel\n",
        "blue = image_rgb[:,:,2] # get red channel\n",
        "\n",
        "cv2.imshow(\"Image\", image_rgb)\n",
        "cv2.waitKey(0) # wait for the user to press a key\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "T_VDh2HdY4lQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Video capture from camera"
      ],
      "metadata": {
        "id": "NrarSNrnuZPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "if not cap.isOpened():\n",
        "    print(\"Cannot open camera\")\n",
        "    exit()\n",
        "while True:\n",
        "    # capture frame-by-frame\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
        "        break\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    cv2.imshow('frame', gray)\n",
        "    if cv2.waitKey(1) == ord('q'):\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "4D1VUyprmUkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Video file processing"
      ],
      "metadata": {
        "id": "AQ-m3rYrn1MO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture('Video.mp4')\n",
        "count = 0\n",
        "frame_number = []\n",
        "\n",
        "def func():\n",
        "  print(\"func\")\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret,img = cap.read()\n",
        "    if ret==True:\n",
        "        img = img[10:-70,200:-230,:]\n",
        "        height,width = img.shape[:2]\n",
        "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "        gray = cv2.medianBlur(gray,17)\n",
        "        cv2.circle(gray,(20,50),20,255,thickness=-1)\n",
        "        try:\n",
        "          func()\n",
        "        except:\n",
        "          print(\"exception\")\n",
        "\n",
        "        frame_number.append(count)\n",
        "        cv2.putText(img,'Frame= '+str(count),(50,50),cv2.FONT_HERSHEY_SIMPLEX,fontScale=1,color=(0,0,0),thickness=2)\n",
        "        cv2.imshow('Pressure Gauge',img)\n",
        "        count = count + 1\n",
        "\n",
        "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "            # save data and exit\n",
        "            output_df = pd.DataFrame({'Frame': np.asarray(frame_number,dtype=int)})\n",
        "            output_df.to_csv('test2.csv',index=False)\n",
        "            break\n",
        "        print(ret)\n",
        "    else:\n",
        "        print('Video finished')\n",
        "\n",
        "print('Exiting...')\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "UlQWJ7LgmUpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save processed video"
      ],
      "metadata": {
        "id": "19skadKdugfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read data\n",
        "dst_images = sorted(glob.glob('dst_data/frames/*.jpg'))\n",
        "\n",
        "i = 71\n",
        "img_M = cv2.imread(dst_images[i])\n",
        "img_M = cv2.cvtColor(img_M,cv2.COLOR_BGR2RGB)\n",
        "h,w = img_M.shape[:2]\n",
        "\n",
        "# build a frame\n",
        "frame_width = 1024\n",
        "frame_height = 768\n",
        "frame = 50*np.ones((frame_height,frame_width,3),dtype=np.uint8)\n",
        "\n",
        "frame[100:100+h,50:50+w,:] = img_M\n",
        "cv2.putText(frame,'M:',(50,100),cv2.FONT_HERSHEY_SIMPLEX,1,(250,250,250),2,cv2.LINE_AA)\n",
        "print(frame.shape,frame.dtype)\n",
        "\n",
        "fig = plt.figure(figsize=(10,8), dpi=80)\n",
        "plt.imshow(frame)\n",
        "plt.title('Output frame')\n",
        "plt.show()\n",
        "\n",
        "# write a video file\n",
        "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
        "framerate = 1 # frames per second\n",
        "out = cv2.VideoWriter('dst_data/output_video/vid.avi',fourcc,framerate,(frame_width,frame_height))\n",
        "\n",
        "for i in tqdm(range(len(dst_images))):\n",
        "    frame = 50*np.ones((frame_height,frame_width,3),dtype=np.uint8)\n",
        "    img_M = cv2.imread(dst_images[i])\n",
        "    frame[100:100+h,50:50+w,:] = img_M\n",
        "    cv2.putText(frame,'M:',(50,100),cv2.FONT_HERSHEY_SIMPLEX,1,(250,250,250),2,cv2.LINE_AA)\n",
        "    out.write(frame)\n",
        "out.release()"
      ],
      "metadata": {
        "id": "k4Bt21b8n6cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Camera calibration"
      ],
      "metadata": {
        "id": "t9NFjlqmmVB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://docs.opencv.org/4.x/dc/dbb/tutorial_py_calibration.html\n",
        "# termination criteria\n",
        "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
        "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
        "objp = np.zeros((6*7,3), np.float32)\n",
        "objp[:,:2] = np.mgrid[0:7,0:6].T.reshape(-1,2)\n",
        "# arrays to store object points and image points from all the images.\n",
        "objpoints = [] # 3d point in real world space\n",
        "imgpoints = [] # 2d points in image plane.\n",
        "images = glob.glob('*.jpg')\n",
        "for fname in images:\n",
        "    img = cv2.imread(fname)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    # find the chess board corners\n",
        "    ret, corners = cv2.findChessboardCorners(gray, (7,6), None)\n",
        "    # if found, add object points, image points (after refining them)\n",
        "    if ret == True:\n",
        "        objpoints.append(objp)\n",
        "        corners2 = cv2.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n",
        "        imgpoints.append(corners2)\n",
        "        # Draw and display the corners\n",
        "        cv2.drawChessboardCorners(img, (7,6), corners2, ret)\n",
        "        cv2.imshow('img', img)\n",
        "        cv2.waitKey(500)\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "VF6S5hLkmXri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# camera calibration\n",
        "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)"
      ],
      "metadata": {
        "id": "VIVUn0gizlUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# undistortion\n",
        "img = cv2.imread('left12.jpg')\n",
        "h,  w = img.shape[:2]\n",
        "newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
        "\n",
        "# undistort\n",
        "dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
        "# crop the image\n",
        "x, y, w, h = roi\n",
        "dst = dst[y:y+h, x:x+w]\n",
        "cv2.imwrite('calibresult.png', dst)"
      ],
      "metadata": {
        "id": "9xKSpodxzmuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# re-projection error (optimal is zero)\n",
        "mean_error = 0\n",
        "for i in range(len(objpoints)):\n",
        "    imgpoints2, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
        "    error = cv2.norm(imgpoints[i], imgpoints2, cv2.NORM_L2)/len(imgpoints2)\n",
        "    mean_error += error\n",
        "print(\"total error: {}\".format(mean_error/len(objpoints)))"
      ],
      "metadata": {
        "id": "2aZQ2VT90EKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://osf.io/9na7e\n",
        "class RCamera():\n",
        "    def __init__(self):\n",
        "        # intrinsic camera parameters\n",
        "        self.intrinsics = np.array([[1300.42739, 0,    418.781929],\n",
        "                                    [0,    1303.92198, 387.691212],\n",
        "                                    [0,    0,      1]], dtype = \"float32\")\n",
        "        # distortion coefficients\n",
        "        self.dist = np.array([[-4.12480510e-01,2.14136684e-01,\n",
        "                               -1.04182515e-04,-3.40927851e-03,\n",
        "                               -3.67091506e-01]],dtype=\"float32\")\n",
        "        # 2D image points\n",
        "        self.TL_px = (46,241)\n",
        "        self.BL_px = (345,530)\n",
        "        self.TR_px = (390,53)\n",
        "        self.BR_px = (716,250)\n",
        "\n",
        "        # 3D model bed corner points\n",
        "        self.TL_mm = (-45.0, 45.0, 0.0)\n",
        "        self.BL_mm = (-45.0, -45.0, 0.0)\n",
        "        self.TR_mm = (45.0, 45.0, 0.0)\n",
        "        self.BR_mm = (45.0, -45.0, 0.0)\n",
        "\n",
        "        self.corner_bed_points_2d = np.array([self.TL_px,self.TR_px,self.BR_px,self.BL_px],dtype=\"float32\")\n",
        "        self.corner_bed_points_3d = np.array([self.TL_mm,self.TR_mm,self.BR_mm,self.BL_mm],dtype=\"float32\")"
      ],
      "metadata": {
        "id": "mX6QdomdmYG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ArUCo markers generation"
      ],
      "metadata": {
        "id": "vRHzS3JJsTSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tag_size, id = 200, 49\n",
        "\n",
        "img = np.zeros((tag_size, tag_size, 1), dtype=\"uint8\")\n",
        "arucoDict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_50)\n",
        "cv2.aruco.generateImageMarker(arucoDict, id, tag_size, img, 1)\n",
        "plt.imshow(img, cmap=\"gray\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "tfA5XfhsmYKF",
        "outputId": "9030ccd6-22ea-403f-d13b-b89e8d3d15d0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x787865ff4bb0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pDO79nMYmYMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ArUCo markers detection (image)\n",
        "\n",
        "- https://github.com/jatin-47/OctoPrint-ARPrintVisualizer/blob/main/octoprint_ARPrintVisualizer/OctoAR/detect_aruco_images.py\n",
        "- https://github.com/GSNCodes/ArUCo-Markers-Pose-Estimation-Generation-Python\n",
        "- https://aliyasineser.medium.com/aruco-marker-tracking-with-opencv-8cb844c26628\n",
        "- https://mecaruco2.readthedocs.io/en/latest/notebooks_rst/Aruco/aruco_basics_video.html\n",
        "- https://docs.opencv.org/4.x/d5/dae/tutorial_aruco_detection.html"
      ],
      "metadata": {
        "id": "_6MLETsRsUzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import sys"
      ],
      "metadata": {
        "id": "i0Sw4YBu17XR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ARUCO_DICT = {\n",
        "\t\"DICT_4X4_50\": cv2.aruco.DICT_4X4_50,\n",
        "\t\"DICT_4X4_100\": cv2.aruco.DICT_4X4_100,\n",
        "\t\"DICT_4X4_250\": cv2.aruco.DICT_4X4_250,\n",
        "\t\"DICT_4X4_1000\": cv2.aruco.DICT_4X4_1000,\n",
        "\t\"DICT_5X5_50\": cv2.aruco.DICT_5X5_50,\n",
        "\t\"DICT_5X5_100\": cv2.aruco.DICT_5X5_100,\n",
        "\t\"DICT_5X5_250\": cv2.aruco.DICT_5X5_250,\n",
        "\t\"DICT_5X5_1000\": cv2.aruco.DICT_5X5_1000,\n",
        "\t\"DICT_6X6_50\": cv2.aruco.DICT_6X6_50,\n",
        "\t\"DICT_6X6_100\": cv2.aruco.DICT_6X6_100,\n",
        "\t\"DICT_6X6_250\": cv2.aruco.DICT_6X6_250,\n",
        "\t\"DICT_6X6_1000\": cv2.aruco.DICT_6X6_1000,\n",
        "\t\"DICT_7X7_50\": cv2.aruco.DICT_7X7_50,\n",
        "\t\"DICT_7X7_100\": cv2.aruco.DICT_7X7_100,\n",
        "\t\"DICT_7X7_250\": cv2.aruco.DICT_7X7_250,\n",
        "\t\"DICT_7X7_1000\": cv2.aruco.DICT_7X7_1000,\n",
        "\t\"DICT_ARUCO_ORIGINAL\": cv2.aruco.DICT_ARUCO_ORIGINAL,\n",
        "\t\"DICT_APRILTAG_16h5\": cv2.aruco.DICT_APRILTAG_16h5,\n",
        "\t\"DICT_APRILTAG_25h9\": cv2.aruco.DICT_APRILTAG_25h9,\n",
        "\t\"DICT_APRILTAG_36h10\": cv2.aruco.DICT_APRILTAG_36h10,\n",
        "\t\"DICT_APRILTAG_36h11\": cv2.aruco.DICT_APRILTAG_36h11\n",
        "}\n",
        "\n",
        "def aruco_display(corners, ids, rejected, image):\n",
        "    if len(corners) > 0:\n",
        "\t\t# flatten the ArUco IDs list\n",
        "        ids = ids.flatten()\n",
        "        # loop over the detected ArUCo corners\n",
        "        for (markerCorner, markerID) in zip(corners, ids):\n",
        "            # extract the marker corners (which are always returned in\n",
        "            # top-left, top-right, bottom-right, and bottom-left order)\n",
        "            corners = markerCorner.reshape((4, 2))\n",
        "            (topLeft, topRight, bottomRight, bottomLeft) = corners\n",
        "\t\t\t# convert each of the (x, y)-coordinate pairs to integers\n",
        "            topRight = (int(topRight[0]), int(topRight[1]))\n",
        "            bottomRight = (int(bottomRight[0]), int(bottomRight[1]))\n",
        "            bottomLeft = (int(bottomLeft[0]), int(bottomLeft[1]))\n",
        "            topLeft = (int(topLeft[0]), int(topLeft[1]))\n",
        "\n",
        "            cv2.line(image, topLeft, topRight, (255, 0, 0), 2)\n",
        "            cv2.line(image, topRight, bottomRight, (0, 255, 0), 2)\n",
        "            cv2.line(image, bottomRight, bottomLeft, (0, 255, 0), 2)\n",
        "            cv2.line(image, bottomLeft, topLeft, (0, 255, 0), 2)\n",
        "\t\t\t# compute and draw the center (x, y)-coordinates of the ArUco\n",
        "\t\t\t# marker\n",
        "            cX = int((topLeft[0] + bottomRight[0]) / 2.0)\n",
        "            cY = int((topLeft[1] + bottomRight[1]) / 2.0)\n",
        "            cv2.circle(image, (cX, cY), 4, (0, 0, 255), -1)\n",
        "\t\t\t# draw the ArUco marker ID on the image\n",
        "            cv2.putText(image, str(markerID),(topLeft[0], topLeft[1] - 10), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "\t\t\t\t0.5, (0, 255, 0), 2)\n",
        "            print(\"[Inference] ArUco marker ID: {}\".format(markerID))\n",
        "\t\t\t# show the output image\n",
        "    return image\n",
        "\n",
        "\n",
        "def get_centre(corner):\n",
        "    \"\"\"\n",
        "    Returns the centre of a rectangle\n",
        "    \"\"\"\n",
        "    (topLeft, topRight, bottomRight, bottomLeft)  = corner.reshape((4, 2))\n",
        "    return int((topLeft[0] + bottomRight[0]) / 2.0), int((topLeft[1] + bottomRight[1]) / 2.0)\n",
        "\n",
        "\n",
        "\n",
        "def get_rec_points(corners):\n",
        "    \"\"\"\n",
        "    Return the four corners of the rectangle that is formed by the centre of the detected four aruco markers\n",
        "    \"\"\"\n",
        "    if len(corners) == 4:\n",
        "        points = []\n",
        "        for corner in corners:\n",
        "            points.append(get_centre(corner))\n",
        "        #sort based on y value\n",
        "        points.sort(key=lambda x: x[1])\n",
        "        #sort based on x value\n",
        "        points[0:2] = sorted(points[0:2], key=lambda x: x[0])\n",
        "        points[2:4] = sorted(points[2:4], key=lambda x: x[0], reverse=True)\n",
        "\n",
        "        points = np.array(points)\n",
        "        points = np.int32(points)\n",
        "        return points\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "lSeN7XfJ2Fo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# python detect_aruco_images.py --image Images/1.png --type DICT_6X6_250"
      ],
      "metadata": {
        "id": "e0fdP3gl2oOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread(\"img.jpeg\")\n",
        "h, w, _ = image.shape\n",
        "width = 1000\n",
        "height = int(width*(h/w))\n",
        "frame = cv2.resize(image, (width, height), interpolation=cv2.INTER_CUBIC)\n",
        "img_gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "# verify that the supplied ArUCo tag exists and is supported by OpenCV\n",
        "if ARUCO_DICT.get(\"DICT_6X6_250\", None) is None:\n",
        "    print(f\"ArUCo tag type '{'DICT_6X6_250'}' is not supported\")\n",
        "    sys.exit(0)\n",
        "\n",
        "# load the ArUCo dictionary, grab the ArUCo parameters, and detect the markers\n",
        "print(\"Detecting '{}' tags....\".format(\"DICT_6X6_250\"))\n",
        "arucoDict = cv2.aruco.Dictionary_get(ARUCO_DICT[\"DICT_6X6_250\"])\n",
        "arucoParams = cv2.aruco.DetectorParameters_create()\n",
        "\n",
        "corners, ids, rejected = cv2.aruco.detectMarkers(img_gray, arucoDict, parameters=arucoParams)\n",
        "detected_markers = cv2.aruco.drawDetectedMarkers(frame, corners, ids)\n",
        "\n",
        "#camera_matrix = np.load(\"calibration_matrix.npy\")\n",
        "#dist_coeffs = np.load(\"distortion_coefficients.npy\")\n",
        "\n",
        "points = get_rec_points(corners)\n",
        "if points is not None:\n",
        "    for point in points:\n",
        "        cv2.circle(frame, tuple(point), 4, (0, 0, 255), -1)\n",
        "\n",
        "    org_h, org_w = 16.5, 18.5 #in cm\n",
        "    points_3D = np.array([[-org_w/2, org_h/2, 0], [org_w/2, org_h/2, 0], [org_w/2, -org_h/2, 0], [-org_w/2, -org_h/2, 0]], dtype=\"double\")\n",
        "\n",
        "    points_2D = points.astype('float32')\n",
        "    points_3D = points_3D.astype('float32')\n",
        "\n",
        "    success, rvecs, tvecs = cv2.solvePnP(points_3D, points_2D, camera_matrix, dist_coeffs)\n",
        "\n",
        "    len = 5 #in cm\n",
        "    axis = np.float32([[-len/2, -len/2, 0], [-len/2, len/2, 0], [len/2, len/2, 0], [len/2, -len/2, 0],\n",
        "                        [-len/2, -len/2, len], [-len/2, len/2, len], [len/2, len/2, len],[len/2, -len/2, len]])\n",
        "\n",
        "    imgpts_2d, jac = cv2.projectPoints(axis, rvecs, tvecs, camera_matrix, dist_coeffs)\n",
        "    imgpts_2d = np.int32(imgpts_2d).reshape(-1, 2)\n",
        "\n",
        "    frame = cv2.drawContours(frame, [imgpts_2d[:4]], -1, (255, 0, 0), 2)\n",
        "    for i, j in zip(range(4), range(4, 8)):\n",
        "        frame = cv2.line(frame, tuple(imgpts_2d[i]), tuple(imgpts_2d[j]), (255, 0, 0), 2)\n",
        "    frame = cv2.drawContours(frame, [imgpts_2d[4:]], -1, (255, 0, 0), 2)\n",
        "\n",
        "\n",
        "    # points = np.float32(points)\n",
        "    # width = 800\n",
        "    # height = int(width*(org_h/org_w))\n",
        "    # target_points = np.float32([[0, 0], [width, 0], [width, height], [0, height]])\n",
        "\n",
        "    # M = cv2.getPerspectiveTransform(points, target_points)\n",
        "    # warped = cv2.warpPerspective(frame, M, (width, height))\n",
        "\n",
        "    # # cv2.imshow(\"Warped\", warped)\n",
        "\n",
        "cv2.imshow(\"Image\", frame)\n",
        "\n",
        "# # Uncomment to save\n",
        "# cv2.imwrite(\"output_sample.png\",detected_markers)\n",
        "\n",
        "cv2.waitKey(0)"
      ],
      "metadata": {
        "id": "QbluwlaLsVBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GITap9B7sVGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ArUCo markers detection (video)"
      ],
      "metadata": {
        "id": "guRerAqP1e7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# python detect_aruco_video.py --type DICT_6X6_250 --camera False --video test_video.mp4\n",
        "\n",
        "video = cv2.VideoCapture(0)\n",
        "if ARUCO_DICT.get(\"DICT_6X6_250\", None) is None:\n",
        "\tprint(f\"ArUCo tag type '{'DICT_6X6_250'}' is not supported\")\n",
        "\tsys.exit(0)\n",
        "\n",
        "arucoDict = cv2.aruco.Dictionary_get(ARUCO_DICT[\"DICT_6X6_250\"])\n",
        "arucoParams = cv2.aruco.DetectorParameters_create()\n",
        "\n",
        "camera_matrix = np.load(\"calibration_matrix.npy\")\n",
        "dist_coeffs = np.load(\"distortion_coefficients.npy\")\n",
        "\n",
        "while True:\n",
        "\tret, img = video.read()\n",
        "\t# img = cv2.flip(img, 1)\n",
        "\tif ret is False:\n",
        "\t\tbreak\n",
        "\n",
        "\th, w, _ = img.shape\n",
        "\n",
        "\twidth=800\n",
        "\theight = int(width*(h/w))\n",
        "\tframe = cv2.resize(img, (width, height), interpolation=cv2.INTER_CUBIC)\n",
        "\timg_gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "\tcorners, ids, rejected = cv2.aruco.detectMarkers(img_gray, arucoDict, parameters=arucoParams)\n",
        "\tframe = cv2.aruco.drawDetectedMarkers(frame, corners, ids)\n",
        "\n",
        "\tpoints = get_rec_points(corners)\n",
        "\tif points is not None:\n",
        "\t\tfor point in points:\n",
        "\t\t\tcv2.circle(frame, tuple(point), 4, (0, 0, 255), -1)\n",
        "\n",
        "\t\torg_h, org_w = 16.5, 18.5 #in cm\n",
        "\t\tpoints_3D = np.array([[-org_w/2, org_h/2, 0], [org_w/2, org_h/2, 0], [org_w/2, -org_h/2, 0], [-org_w/2, -org_h/2, 0]], dtype=\"double\")\n",
        "\n",
        "\t\tpoints_2D = points.astype('float32')\n",
        "\t\tpoints_3D = points_3D.astype('float32')\n",
        "\n",
        "\t\tsuccess, rvecs, tvecs = cv2.solvePnP(points_3D, points_2D, camera_matrix, dist_coeffs)\n",
        "\n",
        "\t\tlen = 14 #in cm\n",
        "\t\taxis = np.float32([[-len/2, -len/2, 0], [-len/2, len/2, 0], [len/2, len/2, 0], [len/2, -len/2, 0],\n",
        "\t\t\t\t\t\t\t[-len/2, -len/2, len], [-len/2, len/2, len], [len/2, len/2, len],[len/2, -len/2, len]])\n",
        "\n",
        "\t\timgpts_2d, jac = cv2.projectPoints(axis, rvecs, tvecs, camera_matrix, dist_coeffs)\n",
        "\t\timgpts_2d = np.int32(imgpts_2d).reshape(-1, 2)\n",
        "\n",
        "\t\tframe = cv2.drawContours(frame, [imgpts_2d[:4]], -1, (255, 0, 0), 2)\n",
        "\t\tfor i, j in zip(range(4), range(4, 8)):\n",
        "\t\t\tframe = cv2.line(frame, tuple(imgpts_2d[i]), tuple(imgpts_2d[j]), (0, 255, 10), 2)\n",
        "\t\tframe = cv2.drawContours(frame, [imgpts_2d[4:]], -1, (255, 0, 0), 2)\n",
        "\n",
        "\t\tpoints = np.float32(points)\n",
        "\t\twidth = 800\n",
        "\t\theight = int(width*(org_h/org_w))\n",
        "\t\ttarget_points = np.float32([[0, 0], [width, 0], [width, height], [0, height]])\n",
        "\n",
        "\t\tM = cv2.getPerspectiveTransform(points, target_points)\n",
        "\t\twarped = cv2.warpPerspective(frame, M, (width, height))\n",
        "\n",
        "\t\tcv2.imshow(\"Warped\", warped)\n",
        "\tcv2.imshow(\"Image\", frame)\n",
        "\n",
        "\tkey = cv2.waitKey(1) & 0xFF\n",
        "\tif key == ord(\"q\"):\n",
        "\t\tbreak\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "video.release()"
      ],
      "metadata": {
        "id": "-c6W6dt4sVJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pose estimation"
      ],
      "metadata": {
        "id": "K0DnFk6BsVSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pose_esitmation(frame, aruco_dict_type, matrix_coefficients, distortion_coefficients):\n",
        "\n",
        "    '''\n",
        "    frame - Frame from the video stream\n",
        "    matrix_coefficients - Intrinsic matrix of the calibrated camera\n",
        "    distortion_coefficients - Distortion coefficients associated with your camera\n",
        "\n",
        "    return:-\n",
        "    frame - The frame with the axis drawn on it\n",
        "    '''\n",
        "\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    cv2.aruco_dict = cv2.aruco.Dictionary_get(aruco_dict_type)\n",
        "    parameters = cv2.aruco.DetectorParameters_create()\n",
        "\n",
        "\n",
        "    corners, ids, rejected_img_points = cv2.aruco.detectMarkers(gray, cv2.aruco_dict,parameters=parameters)\n",
        "\n",
        "        # If markers are detected\n",
        "    if len(corners) > 0:\n",
        "        for i in range(0, len(ids)):\n",
        "            # Estimate pose of each marker and return the values rvec and tvec---(different from those of camera coefficients)\n",
        "            rvec, tvec, markerPoints = cv2.aruco.estimatePoseSingleMarkers(corners[i], 0.02, matrix_coefficients,\n",
        "                                                                       distortion_coefficients)\n",
        "            # Draw a square around the markers\n",
        "            cv2.aruco.drawDetectedMarkers(frame, corners)\n",
        "\n",
        "            # Draw Axis\n",
        "            cv2.drawFrameAxes(frame, matrix_coefficients, distortion_coefficients, rvec, tvec, 0.01)\n",
        "\n",
        "    return frame\n",
        "\n",
        "    if __name__ == '__main__':\n",
        "\n",
        "    ap = argparse.ArgumentParser()\n",
        "    ap.add_argument(\"-k\", \"--K_Matrix\", required=True, help=\"Path to calibration matrix (numpy file)\")\n",
        "    ap.add_argument(\"-d\", \"--D_Coeff\", required=True, help=\"Path to distortion coefficients (numpy file)\")\n",
        "    ap.add_argument(\"-t\", \"--type\", type=str, default=\"DICT_ARUCO_ORIGINAL\", help=\"Type of ArUCo tag to detect\")\n",
        "    args = vars(ap.parse_args())\n",
        "\n",
        "\n",
        "    if ARUCO_DICT.get(args[\"type\"], None) is None:\n",
        "        print(f\"ArUCo tag type '{args['type']}' is not supported\")\n",
        "        sys.exit(0)\n",
        "\n",
        "    aruco_dict_type = ARUCO_DICT[args[\"type\"]]\n",
        "    calibration_matrix_path = args[\"K_Matrix\"]\n",
        "    distortion_coefficients_path = args[\"D_Coeff\"]\n",
        "\n",
        "    k = np.load(calibration_matrix_path)\n",
        "    d = np.load(distortion_coefficients_path)\n",
        "    print(k)\n",
        "    print(d)\n",
        "    \"\"\"\n",
        "    video = cv2.VideoCapture(1)\n",
        "    time.sleep(2.0)\n",
        "\n",
        "    while True:\n",
        "        ret, frame = video.read()\n",
        "\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        output = pose_esitmation(frame, aruco_dict_type, k, d)\n",
        "\n",
        "        cv2.imshow('Estimated Pose', output)\n",
        "\n",
        "        key = cv2.waitKey(1) & 0xFF\n",
        "        if key == ord('q'):\n",
        "            break\n",
        "\n",
        "    video.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "_fzlBZ-8sVfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OFgQ44UNsVij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perspective projection"
      ],
      "metadata": {
        "id": "KkwfEUJasgmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Image():\n",
        "\n",
        "    def __init__(self):\n",
        "        # dimensions of the unwrapped virtual top view (in pixels)\n",
        "        self.top_width = 601\n",
        "        self.top_height = 601\n",
        "\n",
        "\n",
        "    def read(self,path):\n",
        "        src_rgb = cv2.imread(path,cv2.IMREAD_COLOR)\n",
        "        src_rgb = cv2.cvtColor(src_rgb, cv2.COLOR_BGR2RGB)\n",
        "        return src_rgb\n",
        "\n",
        "\n",
        "    def undistort_image(self,src_rgb,Camera):\n",
        "        h, w = src_rgb.shape[:2]\n",
        "        newcameramtx,roi=cv2.getOptimalNewCameraMatrix(Camera.intrinsics,\\\n",
        "                                                       Camera.dist,(w,h),1,(w,h))\n",
        "        undistorted = cv2.undistort(src_rgb,Camera.intrinsics,\\\n",
        "                                    Camera.dist,None,newcameramtx)\n",
        "        x,y,w,h = roi\n",
        "        return undistorted[y:y+h,x:x+w]\n",
        "\n",
        "\n",
        "    def project_plane(self,slice_height,Camera):\n",
        "        # assuming no lens distortion (image is already undistorted)\n",
        "        dist_coeffs = np.zeros((4,1))\n",
        "        #dist_coeffs = Camera.dist\n",
        "        (_,rotation_vector,translation_vector)=cv2.solvePnP(Camera.corner_bed_points_3d,\\\n",
        "                                                          Camera.corner_bed_points_2d,\\\n",
        "                                                          Camera.intrinsics,\\\n",
        "                                                          dist_coeffs,\\\n",
        "                                                          flags=cv2.cv2.SOLVEPNP_ITERATIVE)\n",
        "\n",
        "        G_plane = np.zeros((4,4),dtype=\"float32\")\n",
        "        G_plane.T[:2] = Camera.corner_bed_points_3d.T[:2] # XY\n",
        "        G_plane.T[2] = (slice_height)*np.ones((4),dtype=\"float32\") # Z\n",
        "        G_plane.T[3] = np.array([0,0,0,1],dtype=\"float32\") # Homogenity\n",
        "\n",
        "        # project G_plane on image\n",
        "        pG_plane = cv2.projectPoints(np.asarray(G_plane[:,0:3],dtype=float),\\\n",
        "                                     rotation_vector,\\\n",
        "                                     translation_vector,\\\n",
        "                                     Camera.intrinsics,dist_coeffs)[0].reshape(-1, 2)\n",
        "        return pG_plane\n",
        "\n",
        "\n",
        "    def unwrap_image(self,undistorted_rgb,corner_points_2d):\n",
        "        rst = np.array(corner_points_2d,dtype=\"float32\")\n",
        "        dst = np.array([[0,0],\n",
        "                        [self.top_width-1,0],\n",
        "                        [self.top_width-1,self.top_height-1],\n",
        "                        [0,self.top_height-1]],dtype = \"float32\")\n",
        "        M = cv2.getPerspectiveTransform(rst,dst)\n",
        "        top_rgb = cv2.warpPerspective(undistorted_rgb,M,\\\n",
        "                                (self.top_width,self.top_height))\n",
        "        return top_rgb\n",
        "\n",
        "\n",
        "    def rotate_layer_slice(self,ot_x,ot_y,ot_z,otheta_x,otheta_y,otheta_z):\n",
        "        # rotation around x, y, and z\n",
        "        oRx=np.array([[1,0,0],[0,np.cos(otheta_x*np.pi/180),-np.sin(otheta_x*np.pi/180)],\\\n",
        "                        [0,np.sin(otheta_x*np.pi/180),np.cos(otheta_x*np.pi/180)]])\n",
        "        oRy=np.array([[np.cos(otheta_y*np.pi/180),0,np.sin(otheta_y*np.pi/180)],[0,1,0],\\\n",
        "                        [-np.sin(otheta_y*np.pi/180),0,np.cos(otheta_y*np.pi/180)]])\n",
        "        oRz=np.array([[np.cos(otheta_z*np.pi/180),-np.sin(otheta_z*np.pi/180),0],\\\n",
        "                        [np.sin(otheta_z*np.pi/180),np.cos(otheta_z*np.pi/180),0],[0,0,1]])\n",
        "\n",
        "        oR = np.dot(np.dot(oRx,oRy),oRz)\n",
        "        ot = np.array([ot_x,ot_y,ot_z])\n",
        "\n",
        "        H = np.zeros((4,4), dtype=\"float32\")\n",
        "        H[0:3,0:3] = oR\n",
        "        H[0:3,3] = ot.T\n",
        "        H[3,3] = 1\n",
        "        return H\n",
        "\n",
        "    def project_layer_slice(self,H,stl_slice,Camera):\n",
        "        # assuming no lens distortion (image is already undistorted)\n",
        "        # distortion should be equal to zero\n",
        "        dist_coeffs = np.zeros((4,1))\n",
        "        (_,rotation_vector,translation_vector)=cv2.solvePnP(Camera.corner_bed_points_3d,\\\n",
        "                                                          Camera.corner_bed_points_2d,\\\n",
        "                                                          Camera.intrinsics,\\\n",
        "                                                          dist_coeffs,\\\n",
        "                                                          flags=cv2.cv2.SOLVEPNP_ITERATIVE)\n",
        "        verts = stl_slice.vertices\n",
        "\n",
        "        G_plane = np.zeros((len(verts),4),dtype=\"float32\")\n",
        "        G_plane.T[:3] = np.asarray(verts).T # XYZ\n",
        "        G_plane.T[3] = np.ones((1,len(verts)),dtype=\"float32\")\n",
        "\n",
        "        # tG_plane -> transformed (rototranslated) G_plane\n",
        "        # ptG_plane -> projected tG_plane\n",
        "        tG_plane = np.zeros((len(verts),4),dtype=np.float32)\n",
        "\n",
        "        # rototranslate G_plane\n",
        "        for i in range(len(verts)):\n",
        "            tG_plane[i] = np.dot(H,G_plane[i])\n",
        "\n",
        "        # project g-code or stl layer plane on the image\n",
        "        ptG_plane = cv2.projectPoints(np.asarray(tG_plane[:,0:3],dtype=float),\\\n",
        "                                      rotation_vector,\\\n",
        "                                      translation_vector,\\\n",
        "                                      Camera.intrinsics,dist_coeffs)[0].reshape(-1, 2)\n",
        "        return ptG_plane\n",
        "\n",
        "\n",
        "    def project_stl_mask(self,H,stl_slice,slice_height,undistorted_rgb,Camera):\n",
        "        # assuming no lens distortion (image is already undistorted)\n",
        "        # distortion should be equal to zero\n",
        "        dist_coeffs = np.zeros((4,1))\n",
        "        (_,rotation_vector,translation_vector)=cv2.solvePnP(Camera.corner_bed_points_3d,\\\n",
        "                                                          Camera.corner_bed_points_2d,\\\n",
        "                                                          Camera.intrinsics,\\\n",
        "                                                          dist_coeffs,\\\n",
        "                                                          flags=cv2.cv2.SOLVEPNP_ITERATIVE)\n",
        "        slice_2D,to_3D = stl_slice.to_planar()\n",
        "        outer_polys = [x.exterior for x in slice_2D.polygons_full]\n",
        "\n",
        "        mask = np.zeros(undistorted_rgb.shape,dtype=np.int32)\n",
        "\n",
        "        for p in (slice_2D.polygons_closed):\n",
        "            if p.exterior in outer_polys:\n",
        "                poly = np.asarray(p.exterior.xy,dtype=np.float32).T\n",
        "                G_plane = np.zeros((len(poly),4),dtype=np.float32)\n",
        "                G_plane.T[:2] = poly.T # XY\n",
        "                G_plane.T[2] = slice_height*np.ones((1,len(poly)),dtype=np.float32) # Z\n",
        "                G_plane.T[3] = np.ones((1,len(poly)),dtype=np.float32)\n",
        "\n",
        "                tG_plane = np.zeros((len(poly),4),dtype=np.float32)\n",
        "                for i in range(len(poly)):\n",
        "                    tG_plane[i] = np.dot(H,G_plane[i])\n",
        "                ptG_plane = cv2.projectPoints(np.asarray(tG_plane[:,0:3],dtype=float),\\\n",
        "                                      rotation_vector,\\\n",
        "                                      translation_vector,\\\n",
        "                                      Camera.intrinsics,dist_coeffs)[0].reshape(-1, 2)\n",
        "                cv2.fillPoly(mask,[np.asarray(ptG_plane,dtype=np.int32)],color =(255,255,255))\n",
        "            else:\n",
        "                poly = np.asarray(p.exterior.xy,dtype=np.float32).T\n",
        "                G_plane = np.zeros((len(poly),4),dtype=np.float32)\n",
        "                G_plane.T[:2] = poly.T # XY\n",
        "                G_plane.T[2] = slice_height*np.ones((1,len(poly)),dtype=np.float32) # Z\n",
        "                G_plane.T[3] = np.ones((1,len(poly)),dtype=np.float32)\n",
        "\n",
        "                tG_plane = np.zeros((len(poly),4),dtype=np.float32)\n",
        "                for i in range(len(poly)):\n",
        "                    tG_plane[i] = np.dot(H,G_plane[i])\n",
        "                ptG_plane = cv2.projectPoints(np.asarray(tG_plane[:,0:3],dtype=float),\\\n",
        "                                      rotation_vector,\\\n",
        "                                      translation_vector,\\\n",
        "                                      Camera.intrinsics,dist_coeffs)[0].reshape(-1, 2)\n",
        "                cv2.fillPoly(mask,[np.asarray(ptG_plane,dtype=np.int32)],color =(0,0,0))\n",
        "        mask = np.asarray((mask/255),dtype=np.uint8)\n",
        "        return mask\n",
        "\n",
        "    def center_bbox(self,top_rgb,top_mask_rgb,size=400):\n",
        "        gray_top = cv2.cvtColor(top_rgb, cv2.COLOR_RGB2GRAY)\n",
        "        gray_mask = top_mask_rgb[:,:,0]\n",
        "\n",
        "        rows = np.any(gray_mask, axis=1)\n",
        "        cols = np.any(gray_mask, axis=0)\n",
        "        rmin, rmax = np.where(rows)[0][[0, -1]]\n",
        "        cmin, cmax = np.where(cols)[0][[0, -1]]\n",
        "\n",
        "        center_x = int(cmin+(cmax-cmin)/2)\n",
        "        center_y = int(rmin+(rmax-rmin)/2)\n",
        "\n",
        "        centered_top = gray_top[int(center_y-size/2):int(center_y+size/2),\n",
        "                               int(center_x-size/2):int(center_x+size/2)]\n",
        "        centered_mask = gray_mask[int(center_y-size/2):int(center_y+size/2),\n",
        "                                  int(center_x-size/2):int(center_x+size/2)]\n",
        "\n",
        "        return centered_top,centered_mask"
      ],
      "metadata": {
        "id": "ycREbQTEsiOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fiZUe4vXsii5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "00RYFCJFsilZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}